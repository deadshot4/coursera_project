{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of finding_suspect.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_w5jvVGcOrcv"
      },
      "source": [
        "# First things first\n",
        "* Click **File -> Save a copy in Drive** and click **Open in new tab** in the pop-up window to save your progress in Google Drive.\n",
        "* Click **Runtime -> Change runtime type** and select **GPU** in Hardware accelerator box to enable faster GPU training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhsw1DXmXK_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K8gN_VVcOrcw"
      },
      "source": [
        "# Final project: Finding the suspect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L2Vwp55tOrcx"
      },
      "source": [
        "<a href=\"https://en.wikipedia.org/wiki/Facial_composite\">Facial composites</a> are widely used in forensics to generate images of suspects. Since victim or witness usually isn't good at drawing, computer-aided generation is applied to reconstruct the face attacker. One of the most commonly used techniques is evolutionary systems that compose the final face from many predefined parts.\n",
        "\n",
        "In this project, we will try to implement an app for creating a facial composite that will be able to construct desired faces without explicitly providing databases of templates. We will apply Variational Autoencoders and Gaussian processes for this task.\n",
        "\n",
        "The final project is developed in a way that you can apply learned techniques to real project yourself. We will include the main guidelines and hints, but a great part of the project will need your creativity and experience from previous assignments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iTs2vPH5Orcy"
      },
      "source": [
        "### Setup\n",
        "Load auxiliary files and then install and import the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DvHxpjmoOrcz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "fd093944-ad9d-4da2-f402-7241ce89f246"
      },
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "if IN_COLAB:\n",
        "    print(\"Downloading Colab files\")\n",
        "    ! shred -u setup_google_colab.py\n",
        "    ! wget https://raw.githubusercontent.com/hse-aml/bayesian-methods-for-ml/master/setup_google_colab.py -O setup_google_colab.py\n",
        "    import setup_google_colab\n",
        "    setup_google_colab.load_data_final_project()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Colab files\n",
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2019-08-04 16:01:43--  https://raw.githubusercontent.com/hse-aml/bayesian-methods-for-ml/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1254 (1.2K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   1.22K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-08-04 16:01:43 (281 MB/s) - ‘setup_google_colab.py’ saved [1254/1254]\n",
            "\n",
            "https://raw.githubusercontent.com/hse-aml/bayesian-methods-for-ml/master/week7_(final_project)/utils.py utils.py\n",
            "https://github.com/hse-aml/bayesian-methods-for-ml/releases/download/v0.1/CelebA_VAE_small_8.h5 week7_(final_project)/CelebA_VAE_small_8.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aOjku8W1Orc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "75ceffda-3b7e-49d4-d923-2ab7d8d74c63"
      },
      "source": [
        "! pip install GPy gpyopt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GPy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/4418ee1db50c6e917e399db841c30b95d3c242555272e85473404ab06377/GPy-1.9.8.tar.gz (989kB)\n",
            "\u001b[K     |████████████████████████████████| 993kB 4.8MB/s \n",
            "\u001b[?25hCollecting gpyopt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/40/ca8f080d74d9f4e29069faa944fcfb083e8693b6daaba0f1e4bc65c88650/GPyOpt-1.2.5.tar.gz (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 25.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from GPy) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.6/dist-packages (from GPy) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from GPy) (1.12.0)\n",
            "Collecting paramz>=0.9.0 (from GPy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/37/4abbeb78d30f20d3402887f46e6e9f3ef32034a9dea65d243654c82c8553/paramz-0.9.5.tar.gz (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 21.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.6/dist-packages (from paramz>=0.9.0->GPy) (4.4.0)\n",
            "Building wheels for collected packages: GPy, gpyopt, paramz\n",
            "  Building wheel for GPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPy: filename=GPy-1.9.8-cp36-cp36m-linux_x86_64.whl size=2626104 sha256=1556d410722c786400fb2a57c8b5a11d371dffe3d3b1623aa3caa634c55f1380\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/ee/cd/1c4dd7df63246b1e8de58af6d4457b7aed13509fdc0c918a13\n",
            "  Building wheel for gpyopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpyopt: filename=GPyOpt-1.2.5-cp36-none-any.whl size=83027 sha256=105455cb26c7b054e518f85b7611afbf4984a8f97c84c32581b6a3f44d3c75a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/1d/87/dc02440831ba986b1547dd11a7dcd44e893b0527083066d869\n",
            "  Building wheel for paramz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paramz: filename=paramz-0.9.5-cp36-none-any.whl size=102552 sha256=dd8100601f74d424800e927d4db11d9b8c560b14488ac3386230fe6870dd2675\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/4a/0e/6e0dc85541825f991c431619e25b870d4b812c911214690cf8\n",
            "Successfully built GPy gpyopt paramz\n",
            "Installing collected packages: paramz, GPy, gpyopt\n",
            "Successfully installed GPy-1.9.8 gpyopt-1.2.5 paramz-0.9.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uP4f3F3ROrc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25dcc72d-eb85-4a84-9048-35cca293e9b6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import tensorflow as tf\n",
        "import GPy\n",
        "import GPyOpt\n",
        "import keras\n",
        "from keras.layers import Input, Dense, Lambda, InputLayer, concatenate, Activation, Flatten, Reshape\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D, Deconv2D\n",
        "from keras.losses import MSE\n",
        "from keras.models import Model, Sequential\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.framework import dtypes\n",
        "import utils\n",
        "import os\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "womYDU_OdlGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_folder = 'img_align_celeba/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDXbPn_ndlxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7376fadd-4440-4b63-e000-80477be92109"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(1, 26):\n",
        "    filename = os.path.join(data_folder, '{:06d}.jpg'.format(i+3000))\n",
        "    img = plt.imread(filename)[45:-45:2, 25:-25:2]\n",
        "    plt.subplot(5, 5, i)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-2aa94f13c761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{:06d}.jpg'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1349\u001b[0m                              \u001b[0;34m'with Pillow installed matplotlib can handle '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m                              'more images' % list(handlers))\n\u001b[0;32m-> 1351\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'img_align_celeba/003001.jpg'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hbfs5OcoOrc9"
      },
      "source": [
        "### Grading\n",
        "As some of the final project tasks can be graded only visually, the final assignment is graded using the peer-review procedure. You will be asked to upload your Jupyter notebook on the web and attach a link to it in the submission form. Detailed submission instructions and grading criterions are written at the end of this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m6pozfp6Orc-"
      },
      "source": [
        "## Model description\n",
        "We will first train variational autoencoder on face images to compress them to low dimension. One important feature of VAE is that constructed latent space is dense. That means that we can traverse the latent space and reconstruct any point along our path into a valid face.\n",
        "\n",
        "Using this continuous latent space we can use Bayesian optimization to maximize some similarity function between a person's face in victim/witness's memory and a face reconstructed from the current point of latent space. Bayesian optimization is an appropriate choice here since people start to forget details about the attacker after they were shown many similar photos. Because of this, we want to reconstruct the photo with the smallest possible number of trials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "89a4n8qQOrc_"
      },
      "source": [
        "## Generating faces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ECDvU8mYOrdA"
      },
      "source": [
        "For this task, you will need to use some database of face images. There are multiple datasets available on the web that you can use: for example, <a href=\"http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\">CelebA</a> or <a href=\"http://vis-www.cs.umass.edu/lfw/\">Labeled Faces in the Wild</a>. We used Aligned & Cropped version of CelebA that you can find <a href=\"https://www.dropbox.com/sh/8oqt9vytwxb3s4r/AADSNUu0bseoCKuxuI5ZeTl1a/Img?dl=0&preview=img_align_celeba.zip\">here</a> to pretrain VAE model for you. See optional part of the final project if you wish to train VAE on your own."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wla8AgUtOrdB"
      },
      "source": [
        "<b>Task 1:</b> Train VAE on faces dataset and draw some samples from it. (You can use code from previous assignments. You may also want to use convolutional encoders and decoders as well as tuning hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L_FRN9SaOrdB",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ri61Sqh6OrdE",
        "colab": {}
      },
      "source": [
        "latent_size = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GLv5LgfyOrdK",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "450cc052-61fd-4767-b8e7-b8c35acc8b39"
      },
      "source": [
        "vae, encoder, decoder = utils.create_vae(batch_size=128, latent=latent_size)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "vae.load_weights ('CelebA_VAE_small_8.h5')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-178e81b16672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'CelebA_VAE_small_8.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'CelebA_VAE_small_8.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdB5j4fDaYVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "1022399f-963f-4b20-9338-a08b1fe7e882"
      },
      "source": [
        "df.open ('CelebA_VAE_small_8.h5')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-70ba6294ace2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'CelebA_VAE_small_8.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rjCVeKshOrdM",
        "colab": {}
      },
      "source": [
        "K.set_learning_phase(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z4zJcc2gOrdO",
        "colab": {}
      },
      "source": [
        "latent_placeholder = tf.placeholder(tf.float32, (1, latent_size))\n",
        "decode = decoder(latent_placeholder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIjFwxNNZx0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c2429f55-5b65-45fc-ad81-00fa1895e9d1"
      },
      "source": [
        "np.random.normal(size=(1, latent_size))[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.89152585,  0.57752682, -0.63852667, -1.87214198, -0.10001388,\n",
              "       -0.3414529 , -0.95932728, -1.11593156])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kmLyCeJzOrdQ"
      },
      "source": [
        "#### GRADED 1 (3 points): Draw 25 samples from trained VAE model\n",
        "As the first part of the assignment, you need to become familiar with the trained model. For all tasks, you will only need a decoder to reconstruct samples from a latent space.\n",
        "\n",
        "To decode the latent variable, you need to run ```decode``` operation defined above with random samples from a standard normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n6QG1sMIOrdQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "0dd24279-ea01-41a5-b557-f3380a44558a"
      },
      "source": [
        "### TODO: Draw 25 samples from VAE here\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    z = np.random.normal(size=(1, latent_size))\n",
        "    image = sess.run(decode, feed_dict={latent_placeholder : z})[0] ### YOUR CODE HERE\n",
        "    plt.imshow(np.clip(image, 0, 1))\n",
        "    plt.axis('off')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAJCCAYAAADdrPONAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m_Nkv8xXOrdT"
      },
      "source": [
        "## Search procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-ed6OU8FOrdU"
      },
      "source": [
        "Now that we have a way to reconstruct images, we need to set up an optimization procedure to find a person that will be the most similar to the one we are thinking about. To do so, we need to set up some scoring utility. Imagine that you want to generate an image of Brad Pitt. You start with a small number of random samples, say 5, and rank them according to their similarity to your vision of Brad Pitt: 1 for the worst, 5 for the best. You then rate image by image using GPyOpt that works in a latent space of VAE. For the new image, you need to somehow assign a real number that will show how good this image is. The simple idea is to ask a user to compare a new image with previous images (along with their scores). A user then enters score to a current image.\n",
        "\n",
        "The proposed scoring has a lot of drawbacks, and you may feel free to come up with new ones: e.g. showing user 9 different images and asking a user which image looks the \"best\".\n",
        "\n",
        "Note that the goal of this task is for you to implement a new algorithm by yourself. You may try different techniques for your task and select one that works the best."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PeDzCr5oOrdW"
      },
      "source": [
        "<b>Task 2:</b> Implement person search using Bayesian optimization. (You can use code from the assignment on Gaussian Processes)\n",
        "\n",
        "Note: try varying `acquisition_type` and `acquisition_par` parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0VeSrdJcOrdX",
        "colab": {}
      },
      "source": [
        "class FacialComposit:\n",
        "    def __init__(self, decoder, latent_size):\n",
        "        self.latent_size = latent_size\n",
        "        self.latent_placeholder = tf.placeholder(tf.float32, (1, latent_size))\n",
        "        self.decode = decoder(self.latent_placeholder)\n",
        "        self.samples = None\n",
        "        self.images = None\n",
        "        self.rating = None\n",
        "\n",
        "    def _get_image(self, latent):\n",
        "        img = sess.run(self.decode, \n",
        "                       feed_dict={self.latent_placeholder: latent[None, :]})[0]\n",
        "        img = np.clip(img, 0, 1)\n",
        "        return img\n",
        "\n",
        "    @staticmethod\n",
        "    def _show_images(images, titles):\n",
        "        assert len(images) == len(titles)\n",
        "        clear_output()\n",
        "        plt.figure(figsize=(3*len(images), 3))\n",
        "        n = len(titles)\n",
        "        for i in range(n):\n",
        "            plt.subplot(1, n, i+1)\n",
        "            plt.imshow(images[i])\n",
        "            plt.title(str(titles[i]))\n",
        "            plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    @staticmethod\n",
        "    def _draw_border(image, w=2):\n",
        "        bordred_image = image.copy()\n",
        "        bordred_image[:, :w] = [1, 0, 0]\n",
        "        bordred_image[:, -w:] = [1, 0, 0]\n",
        "        bordred_image[:w, :] = [1, 0, 0]\n",
        "        bordred_image[-w:, :] = [1, 0, 0]\n",
        "        return bordred_image\n",
        "\n",
        "    def query_initial(self, n_start=5, select_top=None):\n",
        "        '''\n",
        "        Creates initial points for Bayesian optimization\n",
        "        Generate *n_start* random images and asks user to rank them.\n",
        "        Gives maximum score to the best image and minimum to the worst.\n",
        "        :param n_start: number of images to rank initialy.\n",
        "        :param select_top: number of images to keep\n",
        "        '''\n",
        "        \n",
        "        samples = np.random.normal(size=(n_start,self.latent_size))\n",
        "        images = np.array([self._get_image(samples[i]) for i in range(n_start)])\n",
        "        \n",
        "        # Show images\n",
        "        self._show_images(images, range(n_start))\n",
        "        print('1 - INITIAL POINTS FOR BAYESIAN OPTIMIZATION')\n",
        "        print('Give maximum score to the best image and minimum to the worst (from 0 to 10, 0 being the worst).\\n')\n",
        "        print('Ex. : \"Rating for IMAGE 0 : 10\" ')\n",
        "        \n",
        "        # Code to select select_top images and rank them from 1 to 5\n",
        "        chosen_idx, rating = [], []\n",
        "        for i in range(select_top):\n",
        "            #print('IMAGE INDEX' + str(i+1) + '/' + str(select_top))\n",
        "            idx = i\n",
        "            chosen_idx.append(int(float(idx)))\n",
        "            rating_x = input('Rating for IMAGE ' + str(i)+ '  :  ')#+'/'+str(select_top)+ ': '\n",
        "            rating.append(int(float(rating_x)))\n",
        "        #print(chosen_idx)\n",
        "        \n",
        "        # Now select images and ratings\n",
        "        \n",
        "        self.samples = np.array(samples[chosen_idx]) ### YOUR CODE HERE (size: select_top x 64 x 64 x 3)\n",
        "        self.images = np.array(images[chosen_idx]) ### YOUR CODE HERE (size: select_top x 64 x 64 x 3)\n",
        "        self.rating = np.array(rating) ### YOUR CODE HERE (size: select_top)\n",
        "        \n",
        "        ### YOUR CODE:\n",
        "        ### Show user some samples (hint: use self._get_image and input())\n",
        "\n",
        "        # Check that tensor sizes are correct\n",
        "        np.testing.assert_equal(self.rating.shape, [select_top])\n",
        "        np.testing.assert_equal(self.images.shape, [select_top, 64, 64, 3])\n",
        "        np.testing.assert_equal(self.samples.shape, [select_top, self.latent_size])\n",
        "\n",
        "    def evaluate(self, candidate):\n",
        "        '''\n",
        "        Queries candidate vs known image set.\n",
        "        Adds candidate into images pool.\n",
        "        :param candidate: latent vector of size 1xlatent_size\n",
        "        '''\n",
        "        initial_size = len(self.images)\n",
        "        candidate_image = self._get_image(candidate[0]).reshape((1, 64, 64, 3))\n",
        "        \n",
        "        init_images_rank = np.argsort(self.rating)[::-1]\n",
        "        init_images_to_display_idx = np.array([init_images_rank[0], init_images_rank[-1]])\n",
        "        init_images_to_display = self.images[init_images_to_display_idx]\n",
        "        ratings_to_display = init_images_rank[init_images_to_display_idx]\n",
        "        #print(init_images_to_display.shape)\n",
        "        #print(candidate_image.shape)\n",
        "        \n",
        "        comparaison = np.append(init_images_to_display, candidate_image, axis=0)\n",
        "        \n",
        "        #print(comparaison.shape)\n",
        "        #print(comparaison) \n",
        "        \n",
        "        self._show_images(comparaison, ['EXISTING BEST', 'EXISTING WORST', 'CANDIDATE'])\n",
        "        #self.draw_best('CURRENT BEST')\n",
        "                          \n",
        "        print('2 - BAYESIAN OPTIMIZATION')\n",
        "        print('Assign rating to candidate images (there will be 10 of them) based on previously shown images.')\n",
        "        #print('Current best: '+str(ratings_to_display[0])+'/10')\n",
        "        ### YOUR CODE HERE\n",
        "        ## Show user an image and ask to assign score to it.\n",
        "        ## You may want to show some images to user along with their scores\n",
        "        ## You should also save candidate, corresponding image and rating\n",
        "        \n",
        "        candidate_rating = int(input('Does the candidate image match our objective? Assign rating to candidate: '))### YOUR CODE HERE\n",
        "        \n",
        "        #print(self.rating.shape)\n",
        "        self.images = np.append(self.images, candidate_image, axis=0)\n",
        "        self.rating = np.append(self.rating, candidate_rating)                                \n",
        "        self.samples = np.append(self.samples, candidate, axis=0)\n",
        "        \n",
        "        assert len(self.images) == initial_size + 1\n",
        "        assert len(self.rating) == initial_size + 1\n",
        "        assert len(self.samples) == initial_size + 1\n",
        "        return candidate_rating\n",
        "\n",
        "    def optimize(self, n_iter=10, w=4, acquisition_type='MPI', acquisition_par=0.3):\n",
        "        if self.samples is None:\n",
        "            self.query_initial()\n",
        "\n",
        "        bounds = [{'name': 'z_{0:03d}'.format(i),\n",
        "                   'type': 'continuous',\n",
        "                   'domain': (-w, w)} \n",
        "                  for i in range(self.latent_size)]\n",
        "        optimizer = GPyOpt.methods.BayesianOptimization(f=self.evaluate, domain=bounds,\n",
        "                                                        acquisition_type = acquisition_type,\n",
        "                                                        acquisition_par = acquisition_par,\n",
        "                                                        exact_eval=False, # Since we are not sure\n",
        "                                                        model_type='GP',\n",
        "                                                        X=self.samples,\n",
        "                                                        Y=self.rating[:, None],\n",
        "                                                        maximize=True)\n",
        "        optimizer.run_optimization(max_iter=n_iter, eps=-1)\n",
        "\n",
        "    def get_best(self):\n",
        "        index_best = np.argmax(self.rating)\n",
        "        return self.images[index_best]\n",
        "\n",
        "    def draw_best(self, title=''):\n",
        "        index_best = np.argmax(self.rating)\n",
        "        image = self.images[index_best]\n",
        "        plt.imshow(image)\n",
        "        plt.title(title)\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "me4go7pXOrdc"
      },
      "source": [
        "#### GRADED 2 (3 points):\n",
        "Describe your approach below: How do you assign a score to a new image? How do you select reference images to help user assign a new score? What are the limitations of your approach?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U3svS-VdOrdc"
      },
      "source": [
        "**bold text**> Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sw52dR9fOrdd"
      },
      "source": [
        "## Testing your algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dz6HxoBaOrde"
      },
      "source": [
        "In these sections, we will apply the implemented app to search for different people. Each task will ask you to generate images that will have some property like \"dark hair\" or \"mustache\". You will need to run your search algorithm and provide the best discovered image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M4pSInvJOrdf"
      },
      "source": [
        "#### Task 3.1: Finding person with darkest hair (3 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X-dHUCanOrdg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "c8d17806-54fe-43d1-cd76-1297d1dc26bb"
      },
      "source": [
        "composit = FacialComposit(decoder, 8)\n",
        "composit.optimize()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAC/CAYAAAB6zqS6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDfwfbJugR57J2qkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x216 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1 - INITIAL POINTS FOR BAYESIAN OPTIMIZATION\n",
            "Give maximum score to the best image and minimum to the worst (from 0 to 10, 0 being the worst).\n",
            "\n",
            "Ex. : \"Rating for IMAGE 0 : 10\" \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ffeabcd55343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcomposit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFacialComposit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcomposit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-93933415595e>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, n_iter, w, acquisition_type, acquisition_par)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquisition_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MPI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquisition_par\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_initial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         bounds = [{'name': 'z_{0:03d}'.format(i),\n",
            "\u001b[0;32m<ipython-input-14-93933415595e>\u001b[0m in \u001b[0;36mquery_initial\u001b[0;34m(self, n_start, select_top)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Code to select select_top images and rank them from 1 to 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mchosen_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_top\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0;31m#print('IMAGE INDEX' + str(i+1) + '/' + str(select_top))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2DxqZwdPOrdl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b6113dc1-ca6a-42e1-d489-ba46f88535b3"
      },
      "source": [
        "composit.draw_best('Darkest hair')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7dfca10e200a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomposit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Darkest hair'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-93933415595e>\u001b[0m in \u001b[0;36mdraw_best\u001b[0;34m(self, title)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mindex_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_best\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wtl3xYbOOrdq"
      },
      "source": [
        "#### Task 3.2. Finding person with the widest smile (3 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Th-Y3kb6Ordr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "21cb1078-89fe-4923-dd35-0523f604617e"
      },
      "source": [
        "composit = FacialComposit(decoder, 8)\n",
        "composit.optimize()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAC/CAYAAAB6zqS6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGQAAQAd0zgAAADrw/4WIu81xDX/7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x216 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1 - INITIAL POINTS FOR BAYESIAN OPTIMIZATION\n",
            "Give maximum score to the best image and minimum to the worst (from 0 to 10, 0 being the worst).\n",
            "\n",
            "Ex. : \"Rating for IMAGE 0 : 10\" \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ffeabcd55343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcomposit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFacialComposit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcomposit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-93933415595e>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, n_iter, w, acquisition_type, acquisition_par)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquisition_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MPI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquisition_par\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_initial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         bounds = [{'name': 'z_{0:03d}'.format(i),\n",
            "\u001b[0;32m<ipython-input-14-93933415595e>\u001b[0m in \u001b[0;36mquery_initial\u001b[0;34m(self, n_start, select_top)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Code to select select_top images and rank them from 1 to 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mchosen_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_top\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0;31m#print('IMAGE INDEX' + str(i+1) + '/' + str(select_top))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WyULC15WOrdt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e72a0430-f027-45a7-bbd2-5d1529ff40b0"
      },
      "source": [
        "composit.draw_best('Widest smile')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-73e7f54595af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomposit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Widest smile'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-93933415595e>\u001b[0m in \u001b[0;36mdraw_best\u001b[0;34m(self, title)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mindex_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_best\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dIt2AbjIOrdv"
      },
      "source": [
        "#### Task 3.3. Finding Daniil Polykovskiy or Alexander Novikov — lecturers of this course (3 points) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D4WWR8TsOrdw"
      },
      "source": [
        "Note: this task highly depends on the quality of a VAE and a search algorithm. You may need to restart your search algorithm a few times and start with larget initial set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uQxSxNyfOrdw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "48481716-7ae1-4dcf-b26d-ea69cff4f7a2"
      },
      "source": [
        "composit = FacialComposit(decoder, 8)\n",
        "composit.optimize()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAC/CAYAAAB6zqS6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAADQgf8HwWGJrjQBFCoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x216 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1 - INITIAL POINTS FOR BAYESIAN OPTIMIZATION\n",
            "Give maximum score to the best image and minimum to the worst (from 0 to 10, 0 being the worst).\n",
            "\n",
            "Ex. : \"Rating for IMAGE 0 : 10\" \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-ffeabcd55343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcomposit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFacialComposit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcomposit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-93933415595e>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, n_iter, w, acquisition_type, acquisition_par)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquisition_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MPI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquisition_par\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_initial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         bounds = [{'name': 'z_{0:03d}'.format(i),\n",
            "\u001b[0;32m<ipython-input-14-93933415595e>\u001b[0m in \u001b[0;36mquery_initial\u001b[0;34m(self, n_start, select_top)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Code to select select_top images and rank them from 1 to 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mchosen_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_top\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0;31m#print('IMAGE INDEX' + str(i+1) + '/' + str(select_top))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7zZuCLJQOrd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "5355ae5e-1bb5-4b72-8780-8ec5205b37e3"
      },
      "source": [
        "composit.draw_best('Lecturer')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f25a219d2511>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomposit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Lecturer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-93933415595e>\u001b[0m in \u001b[0;36mdraw_best\u001b[0;34m(self, title)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mindex_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_best\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ru8T_44GOrd2"
      },
      "source": [
        "#### <small>Don't forget to post resulting image of lecturers on the forum ;)</small>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "15c0hFCyOrd3"
      },
      "source": [
        "#### Task 3.4. Finding specific person (optional, but very cool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PHSAo6_zOrd4"
      },
      "source": [
        "Now that you have a good sense of what your algorithm can do, here is an optional assignment for you. Think of a famous person and take look at his/her picture for a minute. Then use your app to create an image of the person you thought of. You can post it in the forum <a href=\"https://www.coursera.org/learn/bayesian-methods-in-machine-learning/discussions/forums/SE06u3rLEeeh0gq4yYKIVA\">Final project: guess who!</a>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "77HswJGmOrd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "fd98f4f7-9817-4bae-9e07-0f9e66a1145c"
      },
      "source": [
        "composit = FacialComposit(decoder, latent_size=8, nb_images_for_bayesopt=10)\n",
        "composit.optimize()### Your code here"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-0ea7c48d416e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomposit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFacialComposit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_images_for_bayesopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcomposit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m### Your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'nb_images_for_bayesopt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "74eXA5esOrd7"
      },
      "source": [
        "### Submission\n",
        "You need to share this notebook via a link: click `SHARE` (in the top-right corner) $\\rightarrow$ `Get shareable link` and then paste the link into the assignment page.\n",
        "\n",
        "**Note** that the reviewers always see the current version of the notebook, so please do not remove or change the contents of the notebook until the review is done.\n",
        "\n",
        "##### If you are working locally (e.g. using Jupyter instead of Colab)\n",
        "Please upload your notebook to Colab and share it via the link or upload the notebook to any file sharing service (e.g. Dropbox) and submit the link to the notebook through https://nbviewer.jupyter.org/, so by clicking on the link the reviewers will see it's contents (and will not need to download the file)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4kvJQPKkOrd7"
      },
      "source": [
        "### Grading criterions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DDfqh-90Ord8"
      },
      "source": [
        "#### Task 1 (3 points) [samples from VAE]\n",
        "* 0 points: No results were provided here or provided images were not generated by VAE\n",
        "* 1 point: Provided images poorly resemble faces\n",
        "* 2 points: Provided images look like faces, maybe with some artifacts, but all look the same\n",
        "* 3 points: Provided images look like faces, maybe with some artifacts, and look different"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IZUOD-J0Ord9"
      },
      "source": [
        "#### Task 2 (3 points) [training procedure]\n",
        "* 0 points: No result was provided\n",
        "* 1 point: Some algorithm was proposed, but it does not use Bayesian optimization\n",
        "* 2 points: Algorithm was proposed, but there were no details on some important aspects: how to assign a score to a new image / how to you select a new image / what are the limitations of the approach\n",
        "* 3 points: Algorithm was proposed, all questions in the task were answered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ng8DZ9OjOrd9"
      },
      "source": [
        "#### Tasks 3.1-3.3 (3 points each) [search for person]\n",
        "* 0 points: Nothing was provided\n",
        "* 1 point: Resulting image was provided, but some of the required images (evolution & nearest image) are not provided\n",
        "* 2 points: All images are provided, but the resulting image does not have requested property\n",
        "* 3 points: All images are provided, the resulting image has required features (long hair / wide smile / looks like lecturer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MycobvSSOrd-"
      },
      "source": [
        "## Passing grade is 60% (9 points)"
      ]
    }
  ]
}